	.file	1 "xvid_dec.c"
	.section .mdebug.abi32
	.previous
	.text
	.align	2
	.globl	xvid_decore
	.ent	xvid_decore
xvid_decore:
	.frame	$sp,0,$31		# vars= 0, regs= 0/0, args= 0, gp= 0
	.mask	0x00000000,0
	.fmask	0x00000000,0
	.set	noreorder
	.set	nomacro
	
	li	$2,1			# 0x1
	move	$8,$6
	move	$3,$5
	beq	$5,$2,$L4
	move	$6,$7

	li	$2,2			# 0x2
	beq	$3,$2,$L5
	move	$5,$8

	beq	$3,$0,$L10
	move	$4,$8

	j	$31
	li	$2,-1			# 0xffffffffffffffff

$L10:
	lui	$25,%hi(decoder_create)
	addiu	$25,$25,%lo(decoder_create)
	jr	$25
	nop

$L4:
	lui	$25,%hi(decoder_destroy)
	addiu	$25,$25,%lo(decoder_destroy)
	jr	$25
	nop

$L5:
	lui	$25,%hi(decoder_decode)
	addiu	$25,$25,%lo(decoder_decode)
	jr	$25
	nop

	.set	macro
	.set	reorder
	.end	xvid_decore
	.size	xvid_decore, .-xvid_decore
	.section	.rodata.str1.4,"aMS",@progbits,1
	.align	2
$LC0:
	.ascii	"xvid-1.1.3\000"
	.text
	.align	2
	.globl	xvid_global
	.ent	xvid_global
xvid_global:
	.frame	$sp,56,$31		# vars= 16, regs= 1/0, args= 32, gp= 0
	.mask	0x80000000,-8
	.fmask	0x00000000,0
	.set	noreorder
	.set	nomacro
	
	addiu	$sp,$sp,-56
	li	$3,1			# 0x1
	sw	$31,48($sp)
	beq	$5,$3,$L14
	move	$10,$6

	li	$2,2			# 0x2
	beq	$5,$2,$L15
	nop

	beq	$5,$0,$L26
	li	$7,-1			# 0xffffffffffffffff

$L16:
	lw	$31,48($sp)
	move	$2,$7
	j	$31
	addiu	$sp,$sp,56

$L26:
	lb	$2,2($6)
	beq	$2,$3,$L27
	lui	$2,%hi(init_mbcoding_data)

	li	$7,-4			# 0xfffffffffffffffc
$L28:
	lw	$31,48($sp)
	move	$2,$7
	j	$31
	addiu	$sp,$sp,56

$L14:
	lb	$2,2($6)
	bne	$2,$3,$L28
	li	$7,-4			# 0xfffffffffffffffc

	li	$2,65536			# 0x10000
	ori	$2,$2,0x103
	lui	$3,%hi($LC0)
	sw	$2,4($6)
	addiu	$3,$3,%lo($LC0)
	li	$2,128			# 0x80
	sw	$2,12($6)
	sw	$3,8($6)
	sw	$0,16($6)
	move	$7,$0
	lw	$31,48($sp)
	move	$2,$7
	j	$31
	addiu	$sp,$sp,56

$L15:
	lb	$2,2($6)
	bne	$2,$3,$L28
	li	$7,-4			# 0xfffffffffffffffc

	lw	$2,4($6)
	li	$3,2147418112			# 0x7fff0000
	ori	$3,$3,0xffff
	and	$2,$2,$3
	li	$3,4			# 0x4
	lw	$5,76($6)
	li	$7,-3			# 0xfffffffffffffffd
	bne	$2,$3,$L16
	lw	$6,80($6)

	lw	$2,24($10)
	srl	$3,$6,31
	srl	$4,$2,31
	addu	$4,$4,$2
	addu	$3,$3,$6
	sra	$3,$3,1
	sra	$4,$4,1
	mul	$8,$6,$2
	lw	$2,8($10)
	lw	$11,84($10)
	lw	$12,40($10)
	addiu	$9,$10,44
	sw	$2,32($sp)
	addiu	$10,$10,60
	sw	$9,16($sp)
	sw	$10,20($sp)
	sw	$12,24($sp)
	mul	$7,$3,$4
	sw	$11,28($sp)
	addiu	$4,$sp,32
	addu	$3,$7,$8
	addu	$3,$2,$3
	addu	$8,$2,$8
	lui	$2,%hi(image_output)
	move	$7,$5
	sw	$8,40($sp)
	addiu	$2,$2,%lo(image_output)
	jal	$2
	sw	$3,36($sp)

	j	$L16
	move	$7,$0

$L27:
	addiu	$2,$2,%lo(init_mbcoding_data)
	jal	$2
	nop

	bne	$2,$0,$L16
	li	$7,-2			# 0xfffffffffffffffe

	lui	$2,%hi(init_vlc_tables)
	addiu	$2,$2,%lo(init_vlc_tables)
	jal	$2
	nop

	lui	$3,%hi(jz_idct_c)
	addiu	$3,$3,%lo(jz_idct_c)
	lui	$4,%hi(idct)
	lui	$2,%hi(emms_c)
	sw	$3,%lo(idct)($4)
	addiu	$2,$2,%lo(emms_c)
	lui	$4,%hi(emms)
	lui	$3,%hi(xvid_QP_Funcs_C)
	sw	$2,%lo(emms)($4)
	addiu	$3,$3,%lo(xvid_QP_Funcs_C)
	lui	$2,%hi(xvid_QP_Funcs)
	lui	$4,%hi(xvid_QP_Add_Funcs_C)
	sw	$3,%lo(xvid_QP_Funcs)($2)
	addiu	$4,$4,%lo(xvid_QP_Add_Funcs_C)
	lui	$3,%hi(xvid_QP_Add_Funcs)
	lui	$2,%hi(xvid_Init_QP)
	addiu	$2,$2,%lo(xvid_Init_QP)
	jal	$2
	sw	$4,%lo(xvid_QP_Add_Funcs)($3)

	lui	$3,%hi(dequant_h263_intra_mxu)
	addiu	$3,$3,%lo(dequant_h263_intra_mxu)
	lui	$4,%hi(dequant_h263_intra)
	lui	$2,%hi(dequant_h263_inter_c)
	sw	$3,%lo(dequant_h263_intra)($4)
	addiu	$2,$2,%lo(dequant_h263_inter_c)
	lui	$4,%hi(dequant_h263_inter)
	lui	$3,%hi(dequant_mpeg_intra_mxu)
	sw	$2,%lo(dequant_h263_inter)($4)
	addiu	$3,$3,%lo(dequant_mpeg_intra_mxu)
	lui	$4,%hi(dequant_mpeg_intra)
	lui	$2,%hi(dequant_mpeg_inter_c)
	sw	$3,%lo(dequant_mpeg_intra)($4)
	addiu	$2,$2,%lo(dequant_mpeg_inter_c)
	lui	$4,%hi(dequant_mpeg_inter)
	lui	$3,%hi(transfer_8to16copy_c)
	sw	$2,%lo(dequant_mpeg_inter)($4)
	addiu	$3,$3,%lo(transfer_8to16copy_c)
	lui	$4,%hi(transfer_8to16copy)
	lui	$2,%hi(transfer_16to8copy_c)
	sw	$3,%lo(transfer_8to16copy)($4)
	addiu	$2,$2,%lo(transfer_16to8copy_c)
	lui	$4,%hi(transfer_16to8copy)
	lui	$3,%hi(transfer_8to16sub_c)
	sw	$2,%lo(transfer_16to8copy)($4)
	addiu	$3,$3,%lo(transfer_8to16sub_c)
	lui	$4,%hi(transfer_8to16sub)
	lui	$2,%hi(transfer_8to16subro_c)
	sw	$3,%lo(transfer_8to16sub)($4)
	addiu	$2,$2,%lo(transfer_8to16subro_c)
	lui	$4,%hi(transfer_8to16subro)
	lui	$3,%hi(transfer_8to16sub2_c)
	sw	$2,%lo(transfer_8to16subro)($4)
	addiu	$3,$3,%lo(transfer_8to16sub2_c)
	lui	$4,%hi(transfer_8to16sub2)
	lui	$2,%hi(transfer_8to16sub2ro_c)
	sw	$3,%lo(transfer_8to16sub2)($4)
	addiu	$2,$2,%lo(transfer_8to16sub2ro_c)
	lui	$4,%hi(transfer_8to16sub2ro)
	lui	$3,%hi(transfer_16to8add_c)
	sw	$2,%lo(transfer_8to16sub2ro)($4)
	addiu	$3,$3,%lo(transfer_16to8add_c)
	lui	$4,%hi(transfer_16to8add)
	lui	$2,%hi(transfer8x8_copy_c)
	sw	$3,%lo(transfer_16to8add)($4)
	addiu	$2,$2,%lo(transfer8x8_copy_c)
	lui	$4,%hi(transfer8x8_copy)
	lui	$3,%hi(transfer8x4_copy_c)
	sw	$2,%lo(transfer8x8_copy)($4)
	addiu	$3,$3,%lo(transfer8x4_copy_c)
	lui	$4,%hi(transfer8x4_copy)
	lui	$2,%hi(interpolate8x8_halfpel_h_c)
	sw	$3,%lo(transfer8x4_copy)($4)
	addiu	$2,$2,%lo(interpolate8x8_halfpel_h_c)
	lui	$4,%hi(interpolate8x8_halfpel_h)
	lui	$3,%hi(interpolate8x8_halfpel_v_c)
	sw	$2,%lo(interpolate8x8_halfpel_h)($4)
	addiu	$3,$3,%lo(interpolate8x8_halfpel_v_c)
	lui	$4,%hi(interpolate8x8_halfpel_v)
	lui	$2,%hi(interpolate8x8_halfpel_hv_c)
	sw	$3,%lo(interpolate8x8_halfpel_v)($4)
	addiu	$2,$2,%lo(interpolate8x8_halfpel_hv_c)
	lui	$4,%hi(interpolate8x8_halfpel_hv)
	lui	$3,%hi(interpolate8x4_halfpel_h_c)
	sw	$2,%lo(interpolate8x8_halfpel_hv)($4)
	addiu	$3,$3,%lo(interpolate8x4_halfpel_h_c)
	lui	$4,%hi(interpolate8x4_halfpel_h)
	lui	$2,%hi(interpolate8x4_halfpel_v_c)
	sw	$3,%lo(interpolate8x4_halfpel_h)($4)
	addiu	$2,$2,%lo(interpolate8x4_halfpel_v_c)
	lui	$4,%hi(interpolate8x4_halfpel_v)
	lui	$3,%hi(interpolate8x4_halfpel_hv_c)
	sw	$2,%lo(interpolate8x4_halfpel_v)($4)
	addiu	$3,$3,%lo(interpolate8x4_halfpel_hv_c)
	lui	$4,%hi(interpolate8x4_halfpel_hv)
	lui	$2,%hi(interpolate8x8_halfpel_add_c)
	sw	$3,%lo(interpolate8x4_halfpel_hv)($4)
	addiu	$2,$2,%lo(interpolate8x8_halfpel_add_c)
	lui	$4,%hi(interpolate8x8_halfpel_add)
	lui	$3,%hi(interpolate8x8_halfpel_h_add_c)
	sw	$2,%lo(interpolate8x8_halfpel_add)($4)
	addiu	$3,$3,%lo(interpolate8x8_halfpel_h_add_c)
	lui	$4,%hi(interpolate8x8_halfpel_h_add)
	lui	$2,%hi(interpolate8x8_halfpel_v_add_c)
	sw	$3,%lo(interpolate8x8_halfpel_h_add)($4)
	addiu	$2,$2,%lo(interpolate8x8_halfpel_v_add_c)
	lui	$4,%hi(interpolate8x8_halfpel_v_add)
	lui	$3,%hi(interpolate8x8_halfpel_hv_add_c)
	sw	$2,%lo(interpolate8x8_halfpel_v_add)($4)
	addiu	$3,$3,%lo(interpolate8x8_halfpel_hv_add_c)
	lui	$4,%hi(interpolate8x8_halfpel_hv_add)
	lui	$2,%hi(interpolate16x16_lowpass_h_c)
	sw	$3,%lo(interpolate8x8_halfpel_hv_add)($4)
	addiu	$2,$2,%lo(interpolate16x16_lowpass_h_c)
	lui	$4,%hi(interpolate16x16_lowpass_h)
	lui	$3,%hi(interpolate16x16_lowpass_v_c)
	sw	$2,%lo(interpolate16x16_lowpass_h)($4)
	addiu	$3,$3,%lo(interpolate16x16_lowpass_v_c)
	lui	$4,%hi(interpolate16x16_lowpass_v)
	lui	$2,%hi(interpolate16x16_lowpass_hv_c)
	sw	$3,%lo(interpolate16x16_lowpass_v)($4)
	addiu	$2,$2,%lo(interpolate16x16_lowpass_hv_c)
	lui	$4,%hi(interpolate16x16_lowpass_hv)
	lui	$3,%hi(interpolate8x8_lowpass_h_c)
	sw	$2,%lo(interpolate16x16_lowpass_hv)($4)
	addiu	$3,$3,%lo(interpolate8x8_lowpass_h_c)
	lui	$4,%hi(interpolate8x8_lowpass_h)
	lui	$2,%hi(interpolate8x8_lowpass_v_c)
	sw	$3,%lo(interpolate8x8_lowpass_h)($4)
	addiu	$2,$2,%lo(interpolate8x8_lowpass_v_c)
	lui	$4,%hi(interpolate8x8_lowpass_v)
	lui	$3,%hi(interpolate8x8_lowpass_hv_c)
	sw	$2,%lo(interpolate8x8_lowpass_v)($4)
	addiu	$3,$3,%lo(interpolate8x8_lowpass_hv_c)
	lui	$4,%hi(interpolate8x8_lowpass_hv)
	lui	$2,%hi(interpolate8x8_6tap_lowpass_h_c)
	sw	$3,%lo(interpolate8x8_lowpass_hv)($4)
	addiu	$2,$2,%lo(interpolate8x8_6tap_lowpass_h_c)
	lui	$4,%hi(interpolate8x8_6tap_lowpass_h)
	lui	$3,%hi(interpolate8x8_6tap_lowpass_v_c)
	sw	$2,%lo(interpolate8x8_6tap_lowpass_h)($4)
	addiu	$3,$3,%lo(interpolate8x8_6tap_lowpass_v_c)
	lui	$4,%hi(interpolate8x8_6tap_lowpass_v)
	lui	$2,%hi(interpolate8x8_avg2_c)
	sw	$3,%lo(interpolate8x8_6tap_lowpass_v)($4)
	addiu	$2,$2,%lo(interpolate8x8_avg2_c)
	lui	$4,%hi(interpolate8x8_avg2)
	lui	$3,%hi(interpolate8x8_avg4_c)
	sw	$2,%lo(interpolate8x8_avg2)($4)
	addiu	$3,$3,%lo(interpolate8x8_avg4_c)
	lui	$2,%hi(interpolate8x8_avg4)
	sw	$3,%lo(interpolate8x8_avg4)($2)
	lui	$4,%hi(image_brightness_c)
	lui	$2,%hi(colorspace_init)
	addiu	$4,$4,%lo(image_brightness_c)
	lui	$3,%hi(image_brightness)
	addiu	$2,$2,%lo(colorspace_init)
	jal	$2
	sw	$4,%lo(image_brightness)($3)

	lui	$2,%hi(yv12_to_yv12_c)
	addiu	$2,$2,%lo(yv12_to_yv12_c)
	lui	$4,%hi(yv12_to_yv12)
	lui	$3,%hi(rgb555_to_yv12_c)
	sw	$2,%lo(yv12_to_yv12)($4)
	addiu	$3,$3,%lo(rgb555_to_yv12_c)
	lui	$4,%hi(rgb555_to_yv12)
	lui	$2,%hi(rgb565_to_yv12_c)
	sw	$3,%lo(rgb555_to_yv12)($4)
	addiu	$2,$2,%lo(rgb565_to_yv12_c)
	lui	$4,%hi(rgb565_to_yv12)
	lui	$3,%hi(bgr_to_yv12_c)
	sw	$2,%lo(rgb565_to_yv12)($4)
	addiu	$3,$3,%lo(bgr_to_yv12_c)
	lui	$4,%hi(bgr_to_yv12)
	lui	$2,%hi(bgra_to_yv12_c)
	sw	$3,%lo(bgr_to_yv12)($4)
	addiu	$2,$2,%lo(bgra_to_yv12_c)
	lui	$4,%hi(bgra_to_yv12)
	lui	$3,%hi(abgr_to_yv12_c)
	sw	$2,%lo(bgra_to_yv12)($4)
	addiu	$3,$3,%lo(abgr_to_yv12_c)
	lui	$4,%hi(abgr_to_yv12)
	lui	$2,%hi(rgba_to_yv12_c)
	sw	$3,%lo(abgr_to_yv12)($4)
	addiu	$2,$2,%lo(rgba_to_yv12_c)
	lui	$4,%hi(rgba_to_yv12)
	lui	$3,%hi(argb_to_yv12_c)
	sw	$2,%lo(rgba_to_yv12)($4)
	addiu	$3,$3,%lo(argb_to_yv12_c)
	lui	$4,%hi(argb_to_yv12)
	lui	$2,%hi(yuyv_to_yv12_c)
	sw	$3,%lo(argb_to_yv12)($4)
	addiu	$2,$2,%lo(yuyv_to_yv12_c)
	lui	$4,%hi(yuyv_to_yv12)
	lui	$3,%hi(uyvy_to_yv12_c)
	sw	$2,%lo(yuyv_to_yv12)($4)
	addiu	$3,$3,%lo(uyvy_to_yv12_c)
	lui	$4,%hi(uyvy_to_yv12)
	lui	$2,%hi(rgb555i_to_yv12_c)
	sw	$3,%lo(uyvy_to_yv12)($4)
	addiu	$2,$2,%lo(rgb555i_to_yv12_c)
	lui	$4,%hi(rgb555i_to_yv12)
	lui	$3,%hi(rgb565i_to_yv12_c)
	sw	$2,%lo(rgb555i_to_yv12)($4)
	addiu	$3,$3,%lo(rgb565i_to_yv12_c)
	lui	$4,%hi(rgb565i_to_yv12)
	lui	$2,%hi(bgri_to_yv12_c)
	sw	$3,%lo(rgb565i_to_yv12)($4)
	addiu	$2,$2,%lo(bgri_to_yv12_c)
	lui	$4,%hi(bgri_to_yv12)
	lui	$3,%hi(bgrai_to_yv12_c)
	sw	$2,%lo(bgri_to_yv12)($4)
	addiu	$3,$3,%lo(bgrai_to_yv12_c)
	lui	$4,%hi(bgrai_to_yv12)
	lui	$2,%hi(abgri_to_yv12_c)
	sw	$3,%lo(bgrai_to_yv12)($4)
	addiu	$2,$2,%lo(abgri_to_yv12_c)
	lui	$4,%hi(abgri_to_yv12)
	lui	$3,%hi(rgbai_to_yv12_c)
	sw	$2,%lo(abgri_to_yv12)($4)
	addiu	$3,$3,%lo(rgbai_to_yv12_c)
	lui	$4,%hi(rgbai_to_yv12)
	lui	$2,%hi(argbi_to_yv12_c)
	sw	$3,%lo(rgbai_to_yv12)($4)
	addiu	$2,$2,%lo(argbi_to_yv12_c)
	lui	$4,%hi(argbi_to_yv12)
	lui	$3,%hi(yuyvi_to_yv12_c)
	sw	$2,%lo(argbi_to_yv12)($4)
	addiu	$3,$3,%lo(yuyvi_to_yv12_c)
	lui	$4,%hi(yuyvi_to_yv12)
	lui	$2,%hi(uyvyi_to_yv12_c)
	sw	$3,%lo(yuyvi_to_yv12)($4)
	addiu	$2,$2,%lo(uyvyi_to_yv12_c)
	lui	$4,%hi(uyvyi_to_yv12)
	lui	$3,%hi(yv12_to_rgb555_c)
	sw	$2,%lo(uyvyi_to_yv12)($4)
	addiu	$3,$3,%lo(yv12_to_rgb555_c)
	lui	$4,%hi(yv12_to_rgb555)
	lui	$2,%hi(yv12_to_rgb565_c)
	sw	$3,%lo(yv12_to_rgb555)($4)
	addiu	$2,$2,%lo(yv12_to_rgb565_c)
	lui	$4,%hi(yv12_to_rgb565)
	lui	$3,%hi(yv12_to_bgr_c)
	sw	$2,%lo(yv12_to_rgb565)($4)
	addiu	$3,$3,%lo(yv12_to_bgr_c)
	lui	$4,%hi(yv12_to_bgr)
	lui	$2,%hi(yv12_to_bgra_c)
	sw	$3,%lo(yv12_to_bgr)($4)
	addiu	$2,$2,%lo(yv12_to_bgra_c)
	lui	$4,%hi(yv12_to_bgra)
	lui	$3,%hi(yv12_to_abgr_c)
	sw	$2,%lo(yv12_to_bgra)($4)
	addiu	$3,$3,%lo(yv12_to_abgr_c)
	lui	$4,%hi(yv12_to_abgr)
	lui	$2,%hi(yv12_to_rgba_c)
	sw	$3,%lo(yv12_to_abgr)($4)
	addiu	$2,$2,%lo(yv12_to_rgba_c)
	lui	$4,%hi(yv12_to_rgba)
	lui	$3,%hi(yv12_to_argb_c)
	sw	$2,%lo(yv12_to_rgba)($4)
	addiu	$3,$3,%lo(yv12_to_argb_c)
	lui	$4,%hi(yv12_to_argb)
	lui	$2,%hi(yv12_to_yuyv_c)
	sw	$3,%lo(yv12_to_argb)($4)
	addiu	$2,$2,%lo(yv12_to_yuyv_c)
	lui	$4,%hi(yv12_to_yuyv)
	lui	$3,%hi(yv12_to_uyvy_c)
	sw	$2,%lo(yv12_to_yuyv)($4)
	addiu	$3,$3,%lo(yv12_to_uyvy_c)
	lui	$4,%hi(yv12_to_uyvy)
	lui	$2,%hi(yv12_to_rgb555i_c)
	sw	$3,%lo(yv12_to_uyvy)($4)
	addiu	$2,$2,%lo(yv12_to_rgb555i_c)
	lui	$4,%hi(yv12_to_rgb555i)
	lui	$3,%hi(yv12_to_rgb565i_c)
	sw	$2,%lo(yv12_to_rgb555i)($4)
	addiu	$3,$3,%lo(yv12_to_rgb565i_c)
	lui	$4,%hi(yv12_to_rgb565i)
	lui	$2,%hi(yv12_to_bgri_c)
	sw	$3,%lo(yv12_to_rgb565i)($4)
	addiu	$2,$2,%lo(yv12_to_bgri_c)
	lui	$4,%hi(yv12_to_bgri)
	lui	$3,%hi(yv12_to_bgrai_c)
	sw	$2,%lo(yv12_to_bgri)($4)
	addiu	$3,$3,%lo(yv12_to_bgrai_c)
	lui	$4,%hi(yv12_to_bgrai)
	lui	$2,%hi(yv12_to_abgri_c)
	sw	$3,%lo(yv12_to_bgrai)($4)
	addiu	$2,$2,%lo(yv12_to_abgri_c)
	lui	$4,%hi(yv12_to_abgri)
	lui	$3,%hi(yv12_to_rgbai_c)
	sw	$2,%lo(yv12_to_abgri)($4)
	addiu	$3,$3,%lo(yv12_to_rgbai_c)
	lui	$4,%hi(yv12_to_rgbai)
	lui	$2,%hi(yv12_to_argbi_c)
	sw	$3,%lo(yv12_to_rgbai)($4)
	addiu	$2,$2,%lo(yv12_to_argbi_c)
	lui	$4,%hi(yv12_to_argbi)
	lui	$3,%hi(yv12_to_yuyvi_c)
	sw	$2,%lo(yv12_to_argbi)($4)
	addiu	$3,$3,%lo(yv12_to_yuyvi_c)
	lui	$4,%hi(yv12_to_yuyvi)
	lui	$2,%hi(yv12_to_uyvyi_c)
	sw	$3,%lo(yv12_to_yuyvi)($4)
	addiu	$2,$2,%lo(yv12_to_uyvyi_c)
	lui	$4,%hi(yv12_to_uyvyi)
	lui	$3,%hi(calc_cbp_c)
	sw	$2,%lo(yv12_to_uyvyi)($4)
	addiu	$3,$3,%lo(calc_cbp_c)
	lui	$2,%hi(calc_cbp)
	move	$7,$0
	j	$L16
	sw	$3,%lo(calc_cbp)($2)

	.set	macro
	.set	reorder
	.end	xvid_global
	.size	xvid_global, .-xvid_global
	.ident	"GCC: (GNU) 4.1.2"
